#!/bin/bash
# RCSB PDB ChatBot - Server Update Script
# Updates the running container with latest code from GitHub

set -e

echo "ğŸ”„ RCSB PDB ChatBot Server Update Script"
echo "======================================="

# Check if we're in the right directory
if [[ ! -f "docker-compose.yml" ]]; then
    echo "âŒ Error: docker-compose.yml not found. Please run this script from the project directory."
    exit 1
fi

# User data management function
manage_user_data() {
    echo ""
    echo "ğŸ“‚ User Data Management"
    echo "======================"

    # Check if user_data directory exists and has content
    if [[ -d "user_data" ]] && [[ -n "$(ls -A user_data 2>/dev/null)" ]]; then
        echo "ğŸ“Š Current user data found:"
        echo "   Directory: $(pwd)/user_data"
        ls -la user_data/ | grep "\.json$" | wc -l | xargs echo "   Session files:"

        echo ""
        echo "ğŸ”§ How would you like to handle existing user data?"
        echo "   1) Keep existing data (recommended)"
        echo "   2) Backup and clear data"
        echo "   3) Export data and clear"
        echo ""
        read -p "Choose option (1-3, default: 1): " data_choice

        case "${data_choice:-1}" in
            1)
                echo "âœ… Keeping existing user data"
                ;;
            2)
                backup_user_data
                clear_user_data
                ;;
            3)
                export_user_data
                clear_user_data
                ;;
            *)
                echo "âœ… Invalid option, keeping existing data"
                ;;
        esac
    else
        echo "ğŸ“‚ No existing user data found - starting fresh"
    fi
}

# Backup user data function
backup_user_data() {
    local timestamp=$(date +"%Y-%m-%d_%H%M%S")
    local backup_dir="backups/user_data_${timestamp}"

    echo "ğŸ’¾ Creating backup..."
    mkdir -p "${backup_dir}"

    if [[ -d "user_data" ]] && [[ -n "$(ls -A user_data 2>/dev/null)" ]]; then
        cp -r user_data/* "${backup_dir}/" 2>/dev/null || true
        echo "âœ… Backup created: ${backup_dir}"
        echo "   Files backed up: $(ls -1 "${backup_dir}" | wc -l)"
    else
        echo "âš ï¸  No data to backup"
    fi
}

# Export user data function
export_user_data() {
    local timestamp=$(date +"%Y-%m-%d_%H%M%S")
    local export_dir="exports/user_data_${timestamp}"

    echo "ğŸ“¤ Exporting user data..."
    mkdir -p "${export_dir}"

    if [[ -d "user_data" ]] && [[ -n "$(ls -A user_data 2>/dev/null)" ]]; then
        cp -r user_data/* "${export_dir}/" 2>/dev/null || true
        echo "âœ… Data exported to: ${export_dir}"

        # Create a summary file
        echo "# User Data Export Summary" > "${export_dir}/export_summary.md"
        echo "Export Date: $(date)" >> "${export_dir}/export_summary.md"
        echo "Files Exported:" >> "${export_dir}/export_summary.md"
        ls -la "${export_dir}"/*.json 2>/dev/null | awk '{print "- " $9}' >> "${export_dir}/export_summary.md" || true
    else
        echo "âš ï¸  No data to export"
    fi
}

# Clear user data function
clear_user_data() {
    echo ""
    read -p "ğŸ—‘ï¸  Are you sure you want to clear all user data? (y/N): " confirm

    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ -d "user_data" ]]; then
            rm -rf user_data/*
            echo "âœ… User data cleared"
        fi
        # Recreate directory structure
        mkdir -p user_data
        echo "ğŸ“ Empty user_data directory ready"
    else
        echo "âŒ Clear operation cancelled"
    fi
}

# Manage user data before update
manage_user_data

echo ""
echo "ğŸ“¥ Pulling latest changes from GitHub..."
git pull origin main

echo "ğŸ›‘ Stopping current container..."
docker-compose down

echo "ğŸ”¨ Rebuilding container with latest changes..."
docker-compose build --no-cache

echo "ğŸš€ Starting updated container..."
docker-compose up -d

echo "â³ Waiting for container to be ready..."
sleep 10

echo "ğŸ©º Checking container health..."
if docker-compose ps | grep -q "healthy\|Up"; then
    echo "âœ… Container is running!"
    
    # Get the port from .env file or default to 8501
    PORT=$(grep APP_PORT .env 2>/dev/null | cut -d'=' -f2 || echo "8501")
    
    echo ""
    echo "ğŸ§  Setting up RAGFlow Knowledge Base & Assistant..."
    
    # Check if OpenAI API key exists
    if grep -q "OPENAI_API_KEY=" .env && ! grep -q "your-openai-api-key-here" .env; then
        echo "ğŸ“š Syncing knowledge base with latest documents..."
        if python3 knowledge_base/initialize_dataset.py --sync; then
            echo "âœ… Knowledge base sync completed"
            
            echo "ğŸ¤– Creating/updating RAGFlow assistant..."
            if python3 src/ragflow_assistant_manager.py; then
                echo "âœ… Assistant setup completed"
            else
                echo "âš ï¸  Assistant setup failed - check RAGFlow connection"
            fi
        else
            echo "âš ï¸  Knowledge base sync failed - continuing with deployment"
        fi
    else
        echo "âš ï¸  OpenAI API key not configured - skipping knowledge base setup"
        echo "   Add OPENAI_API_KEY to .env file to enable document processing"
    fi
    
    echo ""
    echo "ğŸ‰ Update completed successfully!"
    echo "ğŸ“± Application should be accessible at:"
    echo "   - Local: http://localhost:${PORT}"
    echo "   - Server: http://$(curl -s ifconfig.me):${PORT}"
    echo ""
    echo "ğŸ“Š Container status:"
    docker-compose ps
    
else
    echo "âŒ Container health check failed. Please check the logs:"
    echo "   docker-compose logs"
fi

echo ""
echo "ğŸ” To view real-time logs: docker-compose logs -f"
echo "ğŸ›‘ To stop the application: docker-compose down"